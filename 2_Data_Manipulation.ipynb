{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Data Manipulation**"
      ],
      "metadata": {
        "id": "BHbjLSxoJtUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Data Cleaning\n",
        "- Data cleaning is a crucial step in the data preprocessing pipeline. It involves handling missing data, removing duplicates, and ensuring that data types are appropriate for analysis.\n",
        "- Data cleaning is a critical process in data manipulation that involves preparing data for analysis by addressing various issues. It ensures the data is accurate, consistent, and usable. Key aspects of data cleaning include handling missing data, removing duplicates, and converting data types."
      ],
      "metadata": {
        "id": "-7mBXtxCJwnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Missing Data\n",
        "- Handling missing data is essential to maintain the integrity of your dataset. Missing values can arise due to various reasons, such as data entry errors or incomplete data collection. There are several strategies for handling missing data:"
      ],
      "metadata": {
        "id": "lITMbwIfP3Z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop Missing Values:\n",
        "\n",
        "\n",
        "- Removing rows or columns with missing values can be effective when the amount of missing data is small and does not significantly impact the dataset. This approach ensures that only complete cases are used in analysis."
      ],
      "metadata": {
        "id": "M5ovbNVFOY-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iyr5XyJQJlDe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', None],\n",
        "    'Age': [25, None, 35, 28],\n",
        "    'City': ['Bangalore', 'Chennai', None, 'Hyderabad']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Drop rows with any missing values\n",
        "df_cleaned = df.dropna()\n",
        "print(df_cleaned)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fill Missing Values:\n",
        "- Filling missing values can be done with constants, means, or other strategies:\n",
        "\n",
        "- This method involves replacing missing values with specific values, such as the mean, median, or mode of the column, or using a placeholder like 'Unknown'. This can help in retaining the dataset's size and ensuring that the analysis is based on complete records."
      ],
      "metadata": {
        "id": "5dsl8cgPOg-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Padhmavathi'],\n",
        "    'Age': [25, None, 35, 28],\n",
        "    'City': ['Bangalore', 'Chennai', None, 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Fill missing values with specific values\n",
        "df_filled = df.fillna(value={'Age': df['Age'].mean(), 'City': 'Unknown'})\n",
        "print(df_filled)\n"
      ],
      "metadata": {
        "id": "aFX0EubTOnwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward Fill:\n",
        "\n",
        "- Forward filling is useful for time series or sequential data:\n",
        "- Forward fill (also known as propagation) involves filling missing values with the last known value in the dataset. This method is particularly useful when the assumption is that the most recent observation is the best estimate for missing values.\n",
        "\n",
        "- Use Case: Forward fill is commonly used in time series data where the value at a given point in time is assumed to be consistent until a new value is observed.\n",
        "\n",
        "- How It Works: If a data point is missing, forward fill replaces it with the value of the previous non-missing data point.\n",
        "\n"
      ],
      "metadata": {
        "id": "4pStQafnOpHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Date': ['2024-01-01', '2024-01-02', None, '2024-01-04'],\n",
        "    'Value': [10, None, 30, 40]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Forward fill missing values\n",
        "df_ffill = df.ffill()\n",
        "print(df_ffill)\n"
      ],
      "metadata": {
        "id": "J45qykmBOsOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backward Fill:\n",
        "\n",
        "- Backward filling fills missing values with the next known value:\n",
        "- Backward fill (also known as bfill) involves filling missing values with the next known value in the dataset. This method is useful when the assumption is that the value observed immediately after a missing entry is the best estimate for that missing entry.\n",
        "\n",
        "- Use Case: Backward fill is often used in scenarios where future values are assumed to provide the best estimate for missing values.\n",
        "\n",
        "- How It Works: If a data point is missing, backward fill replaces it with the value of the next non-missing data point."
      ],
      "metadata": {
        "id": "WTpnBjLzOvPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Date': ['2024-01-01', None, '2024-01-03', '2024-01-04'],\n",
        "    'Value': [10, 20, None, 40]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Backward fill missing values\n",
        "df_bfill = df.bfill()\n",
        "print(df_bfill)\n"
      ],
      "metadata": {
        "id": "UJrRpU70Ox97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Removing Duplicates:\n",
        "\n",
        "- Duplicate data can distort analysis, and removing them is crucial:\n",
        "- Duplicate data can distort analysis and lead to inaccurate conclusions. Removing duplicates ensures that each entry is unique and contributes only once to the dataset:"
      ],
      "metadata": {
        "id": "RAfO9o8SO0wR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Duplicate Rows:\n",
        "- This involves deleting duplicate rows in the dataset, leaving only unique entries. This is useful for datasets where duplicate rows may have been introduced through errors or data merging."
      ],
      "metadata": {
        "id": "uIwGnnEjQfUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Duplicate Rows\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Bhagath', 'Monika'],\n",
        "    'Age': [25, 30, 25, 35],\n",
        "    'City': ['Bangalore', 'Chennai', 'Bangalore', 'Hyderabad']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Remove duplicate rows\n",
        "df_no_duplicates = df.drop_duplicates()\n",
        "print(df_no_duplicates)\n",
        "\n"
      ],
      "metadata": {
        "id": "deY78j4VO5Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remove Duplicates Based on Specific Columns:\n",
        "- In some cases, duplicates may need to be removed based on certain columns while keeping others. For example, if multiple records have the same name and age, but different cities, you might choose to keep only unique combinations of these columns."
      ],
      "metadata": {
        "id": "AcxVdCOMQojy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Duplicates Based on Specific Columns\n",
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Bhagath', 'Monika'],\n",
        "    'Age': [25, 30, 25, 35],\n",
        "    'City': ['Bangalore', 'Chennai', 'Bangalore', 'Hyderabad']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Remove duplicates based on Name and Age columns\n",
        "df_no_duplicates = df.drop_duplicates(subset=['Name', 'Age'])\n",
        "print(df_no_duplicates)\n",
        "\n"
      ],
      "metadata": {
        "id": "deJxqfqbO-oH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keep First or Last Occurrence:\n",
        "- When duplicates are present, you can choose to keep either the first or last occurrence of the duplicate entries. This method helps in maintaining the most relevant or recent data while discarding redundant records."
      ],
      "metadata": {
        "id": "plGPgpB9PBon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Bhagath', 'Monika', 'Bhagath'],\n",
        "    'Age': [25, 30, 25, 35, 25],\n",
        "    'City': ['Bangalore', 'Chennai', 'Bangalore', 'Hyderabad', 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Keep the first occurrence of duplicates\n",
        "df_first = df.drop_duplicates(keep='first')\n",
        "print(df_first)\n",
        "\n",
        "# Keep the last occurrence of duplicates\n",
        "df_last = df.drop_duplicates(keep='last')\n",
        "print(df_last)\n"
      ],
      "metadata": {
        "id": "M2T7HIjHPHGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Type Conversion\n",
        "- Ensuring data types are correct is crucial for data manipulation and analysis:\n",
        "\n",
        "## Convert Data Types\n",
        "- Data types need to be correctly set for accurate computations and analyses. For instance, numeric data should be in integer or float format, categorical data should be converted to a categorical type, and date information should be converted to datetime format."
      ],
      "metadata": {
        "id": "Mhf2v3-hPKYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika'],\n",
        "    'Age': ['25', '30', '35']  # Age is in string format\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert Age column to float\n",
        "df['Age'] = df['Age'].astype(float)\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "kbMz08DLPPt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert to Categorical Data\n",
        "\n",
        "-Converting columns to categorical data types can optimize memory usage and improve performance when dealing with categorical variables."
      ],
      "metadata": {
        "id": "RqS6jq0-PRWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Bhagath'],\n",
        "    'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert City column to categorical data type\n",
        "df['City'] = df['City'].astype('category')\n",
        "print(df.dtypes)\n"
      ],
      "metadata": {
        "id": "DZ957n0IPTAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert to DateTime\n",
        "\n",
        "- Converting date-related columns to datetime types enables proper date manipulations, such as filtering by date ranges and calculating time intervals.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zNQIrDT3PUq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Date': ['2024-01-01', '2024-01-02', '2024-01-03'],\n",
        "    'Value': [10, 20, 30]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert Date column to datetime type\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "yUVIYJ7pPZB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Transformation\n",
        "\n",
        "Data transformation involves modifying data to make it more suitable for analysis or to meet specific requirements. This can include tasks like renaming columns, applying functions, and performing aggregation and grouping operations. Here’s a deeper look into these transformations:\n",
        "\n",
        "### Renaming Columns and Indexes\n",
        "\n",
        "Renaming columns and indexes is a common preprocessing step in data cleaning. It helps in making the dataset more understandable and aligns with the conventions used in analysis or reporting.\n",
        "\n",
        "- **Renaming Columns**\n",
        "\n",
        "  Renaming columns allows for clearer labels that better describe the data or fit specific analytical needs. This is particularly useful when integrating data from multiple sources where column names might be inconsistent.\n",
        "\n",
        "  **Theory:** The `rename()` method in Pandas can be used to change column names. It takes a dictionary where keys are the current names and values are the new names. Renaming columns can make data easier to understand and work with.\n",
        "\n",
        "  **Example:**\n",
        "\n",
        "  ```python\n",
        "  import pandas as pd\n",
        "\n",
        "  data = {\n",
        "      'Name': ['Bhagath', 'Bharath', 'Monika', 'Padhmavathi'],\n",
        "      'Age': [25, 30, 35, 28],\n",
        "      'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "  }\n",
        "  df = pd.DataFrame(data)\n",
        "\n",
        "  # Renaming columns\n",
        "  df_renamed = df.rename(columns={'Name': 'Full Name', 'Age': 'Age in Years', 'City': 'City of Residence'})\n",
        "  print(df_renamed)\n"
      ],
      "metadata": {
        "id": "Or-jKPocRaZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Renaming Indexes\n",
        "\n",
        "- Renaming indexes can provide meaningful labels for rows, especially when data represents entities like individuals or locations.\n",
        "\n",
        "- Theory: The rename() method can also be used for renaming row indexes. This helps in identifying rows easily, which is useful for data reporting and analysis."
      ],
      "metadata": {
        "id": "A9hwQDzSTeJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Padhmavathi'],\n",
        "    'Age': [25, 30, 35, 28],\n",
        "    'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Renaming indexes\n",
        "df_renamed_index = df.rename(index={0: 'Person1', 1: 'Person2', 2: 'Person3', 3: 'Person4'})\n",
        "print(df_renamed_index)\n"
      ],
      "metadata": {
        "id": "krips37yTnCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Functions\n",
        "- Applying functions to data allows for transformations and calculations that help in deriving new insights or preparing data for analysis.\n",
        "\n",
        "- Using apply()\n",
        "\n",
        "  - apply() is a versatile method for applying functions along either axis of the DataFrame. This is useful for operations that require processing each element or row/column.\n",
        "\n",
        "  - Theory: The apply() method can be used to perform operations across rows or columns. Functions applied can be user-defined or built-in. It’s particularly useful for custom calculations or transformations."
      ],
      "metadata": {
        "id": "3bhmHPDfTnxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Padhmavathi'],\n",
        "    'Age': [25, 30, 35, 28]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Applying a function to a column\n",
        "df['Age in Months'] = df['Age'].apply(lambda x: x * 12)\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "SFlNtS7kT8qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using map()\n",
        "\n",
        "  - map() is used for element-wise transformations. It’s ideal for replacing values with corresponding values from a dictionary or applying a function to each element.\n",
        "\n",
        "  - The map() function is used to transform data by mapping values from one set to another. This is useful for tasks like replacing categorical data with numerical values or applying a function to each element."
      ],
      "metadata": {
        "id": "krmYBPxIT-YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika'],\n",
        "    'City': ['Bangalore', 'Chennai', 'Hyderabad']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Mapping city names to abbreviations\n",
        "city_map = {\n",
        "    'Bangalore': 'BLR',\n",
        "    'Chennai': 'CHE',\n",
        "    'Hyderabad': 'HYD'\n",
        "}\n",
        "df['City Abbreviation'] = df['City'].map(city_map)\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "iLKl-MmjULWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using applymap()\n",
        "\n",
        "  - applymap() is used to apply a function to every element of the DataFrame. This is useful for performing operations on all values in the DataFrame.\n",
        "\n",
        "  - The applymap() method allows for element-wise operations across the entire DataFrame. This is useful for applying functions to each cell, such as formatting or type conversion."
      ],
      "metadata": {
        "id": "ncROChaMUM47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika'],\n",
        "    'Age': [25, 30, 35]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Applying a function to every element\n",
        "df_uppercase = df.applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
        "print(df_uppercase)\n"
      ],
      "metadata": {
        "id": "dGQZZT5zUS-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregation and Grouping\n",
        "- Aggregation and grouping are used to summarize and analyze data by dividing it into groups and performing calculations on these groups.\n",
        "\n",
        "  ### Using groupby()\n",
        "\n",
        "  - groupby() is used to group data based on one or more columns and perform aggregate operations such as sum, mean, or count.\n",
        "\n",
        "  - The groupby() method splits the data into groups based on specified criteria and then allows for aggregate functions to be applied to each group. This is useful for summarizing data and performing analysis on subsets of the dataset."
      ],
      "metadata": {
        "id": "z9qrJoOGUSS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Bhagath'],\n",
        "    'Age': [25, 30, 35, 25],\n",
        "    'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Grouping by Name and calculating the mean Age\n",
        "df_grouped = df.groupby('Name').agg({'Age': 'mean'})\n",
        "print(df_grouped)\n"
      ],
      "metadata": {
        "id": "iXV0ygFQUdPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ### Using pivot_table()\n",
        "\n",
        "  - pivot_table() allows for creating a pivot table which is a powerful tool for summarizing and analyzing data. It allows for multi-dimensional aggregation and cross-tabulation.\n",
        "\n",
        "  - The pivot_table() method is used to create a table where values are aggregated across multiple dimensions. It’s useful for summarizing large datasets and performing complex analyses."
      ],
      "metadata": {
        "id": "7eAai0ALUfQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Bhagath'],\n",
        "    'Age': [25, 30, 35, 25],\n",
        "    'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating a pivot table\n",
        "df_pivot = pd.pivot_table(df, values='Age', index='Name', aggfunc='mean')\n",
        "print(df_pivot)\n"
      ],
      "metadata": {
        "id": "-SNAKT-CUlqS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}