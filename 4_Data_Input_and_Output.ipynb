{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Data Input and Output**\n",
        "\n",
        "Data input and output (I/O) operations are crucial for reading data from various formats and writing data to different formats. Pandas provides robust methods for handling these operations, allowing you to work with CSV, Excel, and JSON files effectively.\n",
        "\n",
        "#### **Reading Data**\n",
        "\n",
        "1. **CSV Files: `read_csv()`**\n",
        "\n",
        "    - CSV (Comma-Separated Values) files are one of the most widely used formats for tabular data. They are simple text files where each line represents a record, and each record's fields are separated by a comma (or other delimiters). read_csv() is a powerful function that allows pandas to read such files into a DataFrame. This function offers many parameters to handle different file structures, such as custom delimiters, header rows, and missing values.\n",
        "\n",
        "- Advanced Features:\n",
        "\n",
        "  - `Delimiters:` By default, read_csv() uses commas as delimiters, but you can specify other delimiters using the sep parameter (e.g., sep='\\t' for tab-separated files).\n",
        "  - `Handling Headers:` You can skip headers or use a specific row as headers with the header parameter. For example, header=None treats the first row as data rather than headers.\n",
        "  - `Handling Missing Data:` The na_values parameter allows you to specify additional strings to recognize as missing values.\n",
        "\n",
        "   **Example:**\n",
        "\n",
        "   ```python\n",
        "   import pandas as pd\n",
        "\n",
        "   # Reading a CSV file\n",
        "   data = {\n",
        "       'Name': ['Bhagath', 'Bharath', 'Monika', 'Padhmavathi'],\n",
        "       'Age': [25, 30, 35, 28],\n",
        "       'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "   }\n",
        "   df = pd.DataFrame(data)\n",
        "   df.to_csv('people.csv', index=False)\n",
        "\n",
        "   # Reading the CSV file back into a DataFrame\n",
        "   df_read = pd.read_csv('people.csv')\n",
        "   print(df_read)\n"
      ],
      "metadata": {
        "id": "9e8BEJ-DhOTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Excel Files:` read_excel()`**\n",
        "   - JExcel files are popular for storing and manipulating data in spreadsheets. Excel supports multiple sheets, various data types, and complex formatting. The read_excel() function reads Excel files into pandas DataFrames, allowing you to specify sheet names, handle multiple sheets, and parse dates.\n",
        "\n",
        "- Advanced Features:\n",
        "\n",
        "  - `Sheet Handling:` You can specify which sheet to read using the sheet_name parameter. It can be an integer (sheet index), a string (sheet name), or a list (multiple sheets).\n",
        "  - `Date Parsing: `The parse_dates parameter can automatically parse date columns, which simplifies handling date and time data.\n",
        "  - `Data Type Conversion:` The dtype parameter allows specifying data types for columns to ensure data consistency.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "ZEl04BtmhYEc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0WvyrC4hDrW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating and saving an Excel file\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Padhmavathi'],\n",
        "    'Age': [25, 30, 35, 28],\n",
        "    'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df.to_excel('people.xlsx', index=False, sheet_name='Sheet1')\n",
        "\n",
        "# Reading the Excel file back into a DataFrame\n",
        "df_read = pd.read_excel('people.xlsx', sheet_name='Sheet1')\n",
        "print(df_read)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. JSON Files: `read_json()`\n",
        " - JSON (JavaScript Object Notation) is a lightweight format for data interchange, commonly used in web applications and APIs. JSON data is hierarchical and can include nested structures. The read_json() function reads JSON files into pandas DataFrames, supporting various JSON formats and structures.\n",
        "\n",
        "- Advanced Features:\n",
        "\n",
        "  - `Orientations: `The orient parameter specifies the JSON structure. Common options include records (list of dictionaries), split (dictionary with separate keys for index, columns, and data), and index (data organized by index).\n",
        "  - `Handling Nested JSON:` Pandas can handle nested JSON data by normalizing it. You might need additional processing to flatten nested structures.\n",
        "Example:"
      ],
      "metadata": {
        "id": "XU1nn97nhmV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Creating and saving a JSON file\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Padhmavathi'],\n",
        "    'Age': [25, 30, 35, 28],\n",
        "    'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df.to_json('people.json', orient='records', lines=True)\n",
        "\n",
        "# Reading the JSON file back into a DataFrame\n",
        "df_read = pd.read_json('people.json', orient='records', lines=True)\n",
        "print(df_read)\n"
      ],
      "metadata": {
        "id": "66CXfG1fhl_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Writing Data\n",
        "\n",
        "1. To CSV: `to_csv()`\n",
        "\n",
        "  - Writing data to CSV files is essential for exporting and sharing data. The to_csv() function allows exporting DataFrames to CSV files with various options for formatting and handling.\n",
        "\n",
        "- Advanced Features:\n",
        "\n",
        "  - `Custom Delimiters:` You can specify custom delimiters using the sep parameter, allowing for various file formats.\n",
        "  - `Index Handling:` The index parameter controls whether the DataFrame index is included in the output file. Setting it to False excludes the index.\n",
        "  - `Compression:` The compression parameter supports various compression formats like gzip, bz2, and zip to save disk space.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "f2yVKE-Bhl4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# DataFrame to be written to CSV\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Padhmavathi'],\n",
        "    'Age': [25, 30, 35, 28],\n",
        "    'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Writing the DataFrame to a CSV file\n",
        "df.to_csv('people_output.csv', index=False)\n"
      ],
      "metadata": {
        "id": "99T8_Zizh47C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. To Excel: `to_excel()`\n",
        "\n",
        "- Exporting data to Excel is useful for generating reports and interacting with users who use spreadsheets. The to_excel() function provides options for saving DataFrames to Excel files with multiple sheets, custom formatting, and additional options.\n",
        "\n",
        "- Advanced Features:\n",
        "\n",
        "  - `Multiple Sheets:` You can write multiple DataFrames to different sheets within the same Excel file using the ExcelWriter context manager.\n",
        "  - `Formatting:` You can use the xlsxwriter engine to apply formatting to the Excel file.\n",
        "Example:"
      ],
      "metadata": {
        "id": "B3SdphgEh6X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# DataFrame to be written to Excel\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Padhmavathi'],\n",
        "    'Age': [25, 30, 35, 28],\n",
        "    'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Writing the DataFrame to an Excel file\n",
        "df.to_excel('people_output.xlsx', index=False, sheet_name='Sheet1')\n"
      ],
      "metadata": {
        "id": "IoLCZx1wh99T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. To JSON: `to_json()`\n",
        "\n",
        "- Writing data to JSON format is useful for interoperability with web applications and APIs. The to_json() function allows exporting DataFrames to JSON files with different structures and options for encoding.\n",
        "\n",
        "- Advanced Features:\n",
        "\n",
        "  - `Orientations:` The orient parameter specifies the structure of the JSON file. Options include records, split, and index, each representing the data in different formats.\n",
        "  - `Indentation:` The indent parameter controls the formatting of the JSON file, making it more readable.\n",
        "\n",
        "Example:"
      ],
      "metadata": {
        "id": "-hCQyESPiAoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# DataFrame to be written to JSON\n",
        "data = {\n",
        "    'Name': ['Bhagath', 'Bharath', 'Monika', 'Padhmavathi'],\n",
        "    'Age': [25, 30, 35, 28],\n",
        "    'City': ['Bangalore', 'Chennai', 'Hyderabad', 'Chickkaballapur']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Writing the DataFrame to a JSON file\n",
        "df.to_json('people_output.json', orient='records', lines=True)\n"
      ],
      "metadata": {
        "id": "BhrFZ0ueiD20"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}